{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "data = keras.datasets.imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words=10000)  # Vocabulary\n",
    "\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = data.get_word_index()\n",
    "\n",
    "word_index = {k: (v + 3) for k, v in word_index.items()}  # Sort the wards as a dict\n",
    "# \"(v+3)\" Because of the three special characters\n",
    "word_index[\"<PAD>\"] = 0  # Space\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # UNK == Unknown\n",
    "word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(val, key) for (key, val) in word_index.items()])  # swipe the dictionary\n",
    "\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                       value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\n",
    "\n",
    "\n",
    "def decode_to_view(text):\n",
    "    \"\"\"\n",
    "    decode to text\n",
    "    :param text:\n",
    "    \"\"\"\n",
    "    return \" \".join([reverse_word_index.get(i, \"?\") for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = keras.Sequential()\\nmodel.add(keras.layers.Embedding(10000, 16))\\nmodel.add(keras.layers.GlobalAveragePooling1D())\\nmodel.add(keras.layers.Dense(16, activation=\"relu\"))  # number of Neurons\\nmodel.add(keras.layers.Dense(1, activation=\"sigmoid\"))\\n\\nmodel.summary()\\n\\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\\n\\nx_val = train_data[:10000]\\nx_train = train_data[10000:]\\n\\ny_val = train_labels[:10000]\\ny_train = train_labels[10000:]\\n\\nfit_model = model.fit(x_train, y_train, epochs=30, batch_size=512, validation_data=(x_val, y_val), verbose=1)\\n\\nresults = model.evaluate(test_data, test_labels)\\nprint(results)\\n\\nmodel.save(\"Model.h5\")\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To load the model\n",
    "\"\"\"\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(10000, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=\"relu\"))  # number of Neurons\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "x_val = train_data[:10000]\n",
    "x_train = train_data[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "y_train = train_labels[10000:]\n",
    "\n",
    "fit_model = model.fit(x_train, y_train, epochs=30, batch_size=512, validation_data=(x_val, y_val), verbose=1)\n",
    "\n",
    "results = model.evaluate(test_data, test_labels)\n",
    "print(results)\n",
    "\n",
    "model.save(\"Model.h5\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_encode(str):\n",
    "    encoded = [1]  # START\n",
    "\n",
    "    for word in str:\n",
    "        if word.lower() in word_index:\n",
    "            encoded.append(word_index[word.lower()])\n",
    "        else:\n",
    "            encoded.append(2)  # UNK\n",
    "    return encoded\n",
    "\n",
    "\n",
    "model = keras.models.load_model(\"Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no way that I could describe my emotions for this movie. I'm totally speechless. Even I laughed (even cried) this much in Marvel movie or even in any movie. I'm fully on my emotion, there are so many tears of joy and loss. Amazing story But I iron man missing now, the acting is outstanding, epic action, great CGI, the best storytelling ever told in a superhero movie, amazing performance. But there is one thing I really hate hate hate the part that Tony Stark a.k.a. iron man died, It's really Make me sad, I must say that I am disappointed. I love it more than 3000. Happiness, sadness, pure joy, excitement... I'm gonna miss this moment in my whole life because let's face it's been awhile movies can bring such a big enthusiasm like this. It is such an experience you'll gonna remember it forever. People are laughing, crying, hate, full of a state emotion. It's 3 hours long but it went by like a finger, and now thinking I'm actually in Quantum Realm because it felt like 5 seconds. Even though you know where the story is gonna bring you because it's still a 'superhero movie' but it left me speechless. It's not just a superhero movie, it's more than that.\n",
      "-----------------------------------------------------------------------\n",
      "[[   1   50    9   57   96   15   13  100 1634   61 1438   18   14   20\n",
      "  4604  484 9308   60   13 1498   60 3785   14   76   11 5647   20   42\n",
      "    60   11  101   20 4604 1314   23   61 1426   50   26   38  111 1674\n",
      "     7 1805    5 1937  480   65   21   13 4586  132 1012  150    4  116\n",
      "     9 1339 1711  206   87 1683    4  118 2804  126  579   11    6 3783\n",
      "    20  480  239   21   50    9   31  155   13   66  784  784  784    4\n",
      "   173   15 1223 5315 2544 4586  132 1131   94   66   97   72  619   13\n",
      "   215  135   15   13  244  685   13  119   12   53   74 5083 2652 3907\n",
      "  1050 1805 2318 4604 2146  717   14  561   11   61  226  113   88 1625\n",
      "   393   94   77 5236  102   70  721  141    6  194 4805   40   14   12\n",
      "     9  141   35  585    2 2146  377   12 1437   84   26 1104 2578  784\n",
      "   368    7    6 1110 1426   94  342  634  196   21   12  435   34   40\n",
      "     6 4388    5  150  536 4604  165   11 6621 5513   88   12  421   40\n",
      "   457 1574   60  151   25  124  121    4   65    9 2146  721   25   88\n",
      "    94  131    6 3783   20   21   12  317   72 9308   94   24   43    6\n",
      "  3783   20   94   53   74   15    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "-----------------------------------------------------------------------\n",
      "This review is 98.02% Positive\n"
     ]
    }
   ],
   "source": [
    "with open(\"External_review\", encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        n_line = line.replace(\",\", \"\").replace(\".\", \"\").replace(\"(\", \"\").replace(\")\", \"\") \\\n",
    "            .replace(\":\", \"\").replace(\"\\\"\", \"\").replace(\"'\", \"\").strip().split(\" \")  # Unsigned characters\n",
    "        encode = review_encode(n_line)\n",
    "        encode = keras.preprocessing.sequence.pad_sequences([encode],\n",
    "                                                            value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\n",
    "        \n",
    "        predict = model.predict(encode)\n",
    "        print(line)\n",
    "        print(\"-----------------------------------------------------------------------\")\n",
    "        print(encode)\n",
    "        print(\"-----------------------------------------------------------------------\")\n",
    "        print(f\"This review is {float(predict[0])*100:.2f}% Positive\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
